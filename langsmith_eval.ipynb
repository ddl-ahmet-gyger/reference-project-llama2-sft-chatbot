{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff82205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import textstat\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "from langsmith import Client\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "from langsmith.evaluation import EvaluationResult, RunEvaluator\n",
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "# To Avoid the Error on Jupyter Notebook (RuntimeError: This Event Loop Is Already Running)\n",
    "# Patch Asyncio To Allow Nested Event Loops\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f6c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Bitsandbytes parameters --\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Chat model\n",
    "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    cache_dir = '/mnt/artifacts/llama2-7b-chat',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          cache_dir = '/mnt/artifacts/llama2-7b-chat',\n",
    "                                          trust_remote_code=True)\n",
    "pipe_llama7b_chat = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=750) # set device to run inference on GPU\n",
    "\n",
    "\n",
    "ft_model_name ='subirmansukhani/llama-2-7b-miniguanaco'\n",
    "ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    ft_model_name,\n",
    "    cache_dir = '/mnt/artifacts/llama2-7b-chat-ft',\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f82861",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.config.use_cache = False\n",
    "ft_model.config.pretraining_tp = 1\n",
    "\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(ft_model_name,\n",
    "                                             cache_dir = '/mnt/artifacts/llama2-7b-chat',\n",
    "                                             trust_remote_code=True)\n",
    "pipe_llama7b_ft_chat = pipeline(task=\"text-generation\", model=ft_model, tokenizer=ft_tokenizer, max_length=750) # set device to run inference on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450077f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_if_not_exists(client, dataset_name, example_inputs, description:str=None, has_answer:bool=False):\n",
    "    \"\"\"\n",
    "    Create a dataset if it doesn't exist, and add examples to it.\n",
    "    \n",
    "    Parameters:\n",
    "    - client: The client object used for operations.\n",
    "    - dataset_name: Name of the dataset to check or create.\n",
    "    - example_inputs: List of key-value pairs to add to the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the dataset with the given name already exists\n",
    "    existing_dataset = client.list_datasets(dataset_name=dataset_name)\n",
    "    if existing_dataset and len(list(existing_dataset)) >= 1:\n",
    "        print(f\"A dataset with the name '{dataset_name}' already exists.\")\n",
    "        return\n",
    "    \n",
    "    # If dataset does not exist, create it\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=description,\n",
    "    )\n",
    "    \n",
    "    if has_answer:\n",
    "        for input_prompt, output_answer in example_inputs:\n",
    "            client.create_example(\n",
    "                inputs={\"question\": input_prompt},\n",
    "                outputs={\"answer\": output_answer},\n",
    "                dataset_id=dataset.id,\n",
    "            )\n",
    "    else:\n",
    "        for input_prompt in example_inputs:\n",
    "            client.create_example(\n",
    "                inputs={\"question\": input_prompt},\n",
    "                outputs=None,\n",
    "                dataset_id=dataset.id,\n",
    "            )\n",
    "    \n",
    "    # Print a completion message after adding all examples\n",
    "    print(f\"Dataset '{dataset_name}' has been successfully created and populated with examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9aed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variables for Langsmith\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = str(os.getenv(\"LANGCHAIN_API_KEY\"))\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"llama2-langsmith-eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b1aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the LangSmith Client and LLM\n",
    "\n",
    "client = Client()\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71525ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Create a Dataset (Only Inputs, No Output)\n",
    "\n",
    "example_inputs = [\n",
    "    \"Complete the following Python function that computes the factorial of a number: \\ndef factorial(n):\",\n",
    "    \"Summarize the following paragraph: 'Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \\\"intelligent agents\\\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.'\",\n",
    "    \"Generate a short poem about the beauty of nature.\",\n",
    "    \"You are in a dark room with a single door. There's a switch next to the door. What do you do?\",\n",
    "    \"Write a Python function to check if a given number is prime: \\ndef is_prime(num):\",\n",
    "    \"Explain the concept of neural networks in a simple way suitable for a high school student.\",\n",
    "    \"Compose a haiku about the serenity of a quiet night.\",\n",
    "    \"You are stuck on a deserted island and you find a radio. What's your next move?\",\n",
    "    \"Translate the following English sentence to French: 'The sun sets over the horizon.'\",\n",
    "    \"What are the primary differences between classical and quantum computing?\",\n",
    "    \"Describe the taste of a freshly picked apple.\",\n",
    "    \"You discover a mysterious old book in your attic with a lock on it. How would you approach this situation?\",\n",
    "    \"Write a SQL query to fetch all rows from the 'employees' table where the salary is greater than 50000.\",\n",
    "    \"What is the significance of the Schr√∂dinger's cat thought experiment in quantum mechanics?\",\n",
    "    \"Provide a Python code snippet to merge two dictionaries: \\ndef merge_dicts(dict1, dict2):\",\n",
    "    \"Briefly describe the process of photosynthesis.\",\n",
    "    \"Compose a limerick about a mischievous cat.\",\n",
    "    \"You're faced with a giant maze with a treasure in the center. How would you navigate it?\",\n",
    "    \"Translate the following English sentence to Spanish: 'The night sky is filled with stars.'\",\n",
    "    \"Explain the main components of a computer to someone from the 18th century.\",\n",
    "    \"Describe the sensation of diving into cold water on a hot day.\",\n",
    "    \"You hear a mysterious noise coming from the basement late at night. What's your reaction?\",\n",
    "    \"Provide a JavaScript function to toggle an element's visibility: \\nfunction toggleVisibility(elementId):\",\n",
    "    \"Outline the main events leading to World War II.\",\n",
    "    \"Write a sonnet about the passage of time.\",\n",
    "    \"You come across a talking frog claiming to be a prince. How do you respond?\",\n",
    "    \"Translate the following English phrase to German: 'Life is full of surprises.'\",\n",
    "    \"Discuss the impact of social media on modern communication.\",\n",
    "    \"Describe the aroma of fresh bread baking in an oven.\",\n",
    "    \"You find a time machine with a note saying it can take you to any one moment in history. Where and when do you choose to go?\",\n",
    "    \"Write a Java method to calculate the area of a rectangle: \\npublic double rectangleArea(double length, double width):\",\n",
    "    \"Detail the contributions of Nikola Tesla to the field of electricity.\",\n",
    "    \"Compose a short story about a dragon who loves to read books.\",\n",
    "    \"If you were to explain the internet to William Shakespeare, how would you describe it?\",\n",
    "    \"Describe the key benefits of adopting cloud computing in modern businesses.\",\n",
    "    \"Provide a summary of the principles of effective leadership in a corporate environment.\",\n",
    "    \"Draft an email to employees announcing a new sustainability initiative.\",\n",
    "    \"Outline the main challenges faced by global supply chains in the current economic climate.\",\n",
    "    \"Explain the significance of data analytics in shaping business strategies today.\",\n",
    "    \"Provide a brief overview of the concept of digital transformation and its impact on customer experience.\",\n",
    "    \"Discuss the role of corporate social responsibility (CSR) in enhancing a company's brand image.\",\n",
    "    \"Write a mission statement for a startup focused on renewable energy solutions.\",\n",
    "    \"Summarize the advantages of remote work for both employees and employers.\",\n",
    "    \"Describe the key factors that contribute to a positive organizational culture.\"\n",
    "]\n",
    "\n",
    "\n",
    "dataset_name = \"Input only subjective task dataset\"\n",
    "create_dataset_if_not_exists(client, dataset_name, example_inputs, description='Diverse tasks without answers', has_answer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ed656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a Dataset From a List of Examples (Key-Value Pairs)\n",
    "\n",
    "example_inputs = [\n",
    "    (\"Complete the following Python function that computes the factorial of a number: \\ndef factorial(n):\", \"def factorial(n): \\n if n == 0: \\n return 1 \\n else: \\n return n * factorial(n-1)\"),\n",
    "    (\"Summarize the following paragraph: 'Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \\\"intelligent agents\\\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\", \n",
    "     \"AI is machine intelligence as opposed to natural human or animal intelligence. It's defined as the study of devices that act intelligently to achieve their goals.\"),\n",
    "    (\"You are in a dark room with a single door. There's a switch next to the door. What do you do?\", \"I would flip the switch to see if it turns on a light.\"),\n",
    "    (\"Convert the following statement into a question: 'The Eiffel Tower is located in Paris.'\", \"Where is the Eiffel Tower located?\"),\n",
    "    (\"Rewrite the following sentence in passive voice: 'Cats chase mice.'\", \"Mice are chased by cats.\"),\n",
    "    (\"Define 'photosynthesis'.\", \"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll pigments.\"),\n",
    "    (\"Translate the following to Spanish: 'Hello, how are you?'\", \"Hola, ¬øc√≥mo est√°s?\"),\n",
    "    (\"Solve for \\( x \\) in the equation \\( 2x = 10 \\).\", \"x = 5\"),\n",
    "    (\"What's the capital of Japan?\", \"Tokyo\"),\n",
    "    (\"Briefly explain the theory of relativity.\", \"The theory of relativity, proposed by Einstein, describes the laws of physics in relation to objects moving relative to each other.\"),\n",
    "    (\"Describe the process of evaporation.\", \"Evaporation is the process by which water changes from a liquid to a gas or vapor.\"),\n",
    "    (\"Who wrote 'Romeo and Juliet'?\", \"William Shakespeare\"),\n",
    "    (\"Convert the following statement into a question: 'She plays the piano.'\", \"Does she play the piano?\"),\n",
    "    (\"What do you do if you have a flat tire on a highway?\", \"I would pull over to a safe location, turn on hazard lights, and change the tire if possible or call for assistance.\"),\n",
    "    (\"Explain the term 'metabolism'.\", \"Metabolism is the set of chemical reactions that occur within a living organism to maintain life.\"),\n",
    "    (\"What's the main ingredient in guacamole?\", \"Avocado\"),\n",
    "    (\"Summarize: 'Gravity is a force by which a planet or other body draws objects toward its center. The force of gravity keeps planets in orbit around the sun.'\", \"Gravity is a force that attracts objects to a body's center and keeps planets orbiting the sun.\"),\n",
    "    (\"Convert the following statement into a question: 'She has visited the museum.'\", \"Has she visited the museum?\"),\n",
    "    (\"Describe the function of the heart.\", \"The heart pumps blood throughout the body, supplying oxygen and nutrients to the tissues and removing carbon dioxide and other wastes.\"),\n",
    "    (\"What is the boiling point of water?\", \"100¬∞C or 212¬∞F at 1 atmospheric pressure.\"),\n",
    "    (\"How does photosynthesis benefit plants?\", \"Photosynthesis provides energy to plants and produces oxygen as a byproduct.\"),\n",
    "    (\"Who painted the Mona Lisa?\", \"Leonardo da Vinci\"),\n",
    "    (\"Define 'osmosis'.\", \"Osmosis is the movement of solvent molecules through a selectively permeable membrane into a region of higher solute concentration.\"),\n",
    "    (\"Explain the greenhouse effect.\", \"The greenhouse effect is a natural process where certain gases in the Earth's atmosphere trap heat, preventing it from escaping into space, thus warming the planet.\")\n",
    "]\n",
    "\n",
    "\n",
    "dataset_name = \"Tasks and Answers\"\n",
    "create_dataset_if_not_exists(client, dataset_name, example_inputs, description='Diverse tasks with answers', has_answer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb90c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"<s>[INST] {question} [/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the LLM based evaluation for tasks that do not have answers specified in the dataset\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        # You can specify an evaluator by name/enum.\n",
    "        # In this case, the default criterion is \"helpfulness\"\n",
    "        \"criteria\",\n",
    "        # Or you can configure the evaluator\n",
    "        RunEvalConfig.Criteria(\"harmfulness\"),\n",
    "        RunEvalConfig.Criteria(\"misogyny\"),\n",
    "        RunEvalConfig.Criteria(\n",
    "            {\n",
    "                \"short_informative\": \"Are the answers short and informative? \"\n",
    "                \"Respond Y if they are, N if they're not short and informative.\"\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c217d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'llama2-langsmith-eval_only_q' at:\n",
      "https://smith.langchain.com/o/dcc925e6-6130-54c2-852e-9cbbb51328d6/projects/p/88fa6a66-ce13-445c-a82f-4eca420bcc7a\n",
      "[------------------------------------------------->] 44/44"
     ]
    }
   ],
   "source": [
    "#  Evaluate the Chat LLM on the dataset that has only has tasks and no reference answers\n",
    "\n",
    "llama_llm_chat = HuggingFacePipeline(pipeline=pipe_llama7b_chat)\n",
    "llama_chain_chat = prompt | llama_llm_chat\n",
    "results = await client.arun_on_dataset(\"Input only subjective task dataset\", \n",
    "                                       llama_chain_chat,\n",
    "                                       evaluation=eval_config,\n",
    "                                       project_name=f'{os.environ[\"LANGCHAIN_PROJECT\"]}_only_q',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09d28557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'llama2-langsmith-eval_finetuned_only_q' at:\n",
      "https://smith.langchain.com/o/dcc925e6-6130-54c2-852e-9cbbb51328d6/projects/p/8d8d33ef-7cd3-4517-8b44-a4149278d97b\n",
      "[-------------------------------------------->     ] 40/44"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/functional.py:924: RuntimeWarning: coroutine '_arun_llm_or_chain' was never awaited\n",
      "  lib.cdequantize_blockwise_fp16_nf4(get_ptr(None), get_ptr(A), get_ptr(absmax), get_ptr(out), ct.c_int(blocksize), ct.c_int(n))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 44/44"
     ]
    }
   ],
   "source": [
    "# Evaluate the fine tuned Chat LLM \n",
    "\n",
    "llama_llm_chat_ft = HuggingFacePipeline(pipeline=pipe_llama7b_ft_chat)\n",
    "llama_chain_chat_ft = prompt | llama_llm_chat_ft\n",
    "results = await client.arun_on_dataset(\"Input only subjective task dataset\",\n",
    "                                       llama_chain_chat_ft,\n",
    "                                       evaluation=eval_config,\n",
    "                                       project_name=f'{os.environ[\"LANGCHAIN_PROJECT\"]}_finetuned_only_q',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c96b7b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's define a custom Flesch Kincaid metric\n",
    "\n",
    "class FKEvaluator(RunEvaluator):\n",
    "    def __init__(self):\n",
    "        self.metric_fn = textstat.flesch_kincaid_grade\n",
    "\n",
    "    def evaluate_run(\n",
    "        self, run: Run, example: Optional[Example] = None\n",
    "    ) -> EvaluationResult:\n",
    "        if run.outputs is None:\n",
    "            raise ValueError(\"Run outputs cannot be None\")\n",
    "#         prediction = run.outputs['generations'][0][0]['text']\n",
    "        prediction = run.outputs['output']\n",
    "        return EvaluationResult(key=\"flesch_kincaid_grade\", score=self.metric_fn(prediction))\n",
    "    \n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        # You can define an arbitrary criterion as a key: value pair in the criteria dict\n",
    "        \"string_distance\",\n",
    "        \"embedding_distance\",\n",
    "        RunEvalConfig.LabeledCriteria(\n",
    "            {\n",
    "                \"helpfulness\": (\n",
    "                    \"Is this submission helpful to the user,\"\n",
    "                    \" taking into account the correct reference answer?\"\n",
    "                )\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    custom_evaluators = [FKEvaluator()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b4d0acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'llama2-langsmith-eval_qa' at:\n",
      "https://smith.langchain.com/o/dcc925e6-6130-54c2-852e-9cbbb51328d6/projects/p/4e68626d-25b7-4055-a462-e70d6a8ef399\n",
      "[------------------------------------------------->] 24/24"
     ]
    }
   ],
   "source": [
    "#  Evaluate the Chat LLM on the dataset that has tasks and reference answers\n",
    "\n",
    "results = await client.arun_on_dataset(\"Tasks and Answers\",\n",
    "                                       llama_chain_chat,\n",
    "                                       evaluation=eval_config,\n",
    "                                       project_name=f'{os.environ[\"LANGCHAIN_PROJECT\"]}_qa',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af4b713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'llama2-langsmith-eval_finetuned_qa' at:\n",
      "https://smith.langchain.com/o/dcc925e6-6130-54c2-852e-9cbbb51328d6/projects/p/2ead0bb7-bbc6-4b90-ac39-4043bd62a973\n",
      "[------------------------------------------------->] 24/24"
     ]
    }
   ],
   "source": [
    "#  Evaluate the fine tuned Chat LLM on the dataset that has tasks and reference answers\n",
    "\n",
    "results = await client.arun_on_dataset(\"Tasks and Answers\",\n",
    "                                       llama_chain_chat_ft,\n",
    "                                       evaluation=eval_config,\n",
    "                                       project_name=f'{os.environ[\"LANGCHAIN_PROJECT\"]}_finetuned_qa',\n",
    "                                      )"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
