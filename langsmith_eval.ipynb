{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81446c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from langsmith import Client\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "# To Avoid the Error on Jupyter Notebook (RuntimeError: This Event Loop Is Already Running)\n",
    "# Patch Asyncio To Allow Nested Event Loops\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df809d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Bitsandbytes parameters --\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Chat model\n",
    "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    cache_dir = '/mnt/artifacts/llama2-7b-chat',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "pipe_llama7b_chat = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=750) # set device to run inference on GPU\n",
    "\n",
    "\n",
    "ft_model_name ='subirmansukhani/llama-2-7b-miniguanaco'\n",
    "ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    ft_model_name,\n",
    "    cache_dir = '/mnt/artifacts/llama2-7b-chat-ft',\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.config.use_cache = False\n",
    "ft_model.config.pretraining_tp = 1\n",
    "\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(ft_model_name, trust_remote_code=True)\n",
    "pipe_llama7b_ft_chat = pipeline(task=\"text-generation\", model=ft_model, tokenizer=ft_tokenizer, max_length=750) # set device to run inference on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65121f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the LangSmith Client and LLM\n",
    "\n",
    "client = Client()\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e48c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Create a Dataset (Only Inputs, No Output)\n",
    "\n",
    "example_inputs = [\n",
    "    \"Complete the following Python function that computes the factorial of a number: \\ndef factorial(n):\",\n",
    "    \"Summarize the following paragraph: 'Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \\\"intelligent agents\\\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.'\",\n",
    "    \"Generate a short poem about the beauty of nature.\",\n",
    "    \"You are in a dark room with a single door. There's a switch next to the door. What do you do?\",\n",
    "    \"Write a Python function to check if a given number is prime: \\ndef is_prime(num):\",\n",
    "    \"Explain the concept of neural networks in a simple way suitable for a high school student.\",\n",
    "    \"Compose a haiku about the serenity of a quiet night.\",\n",
    "    \"You are stuck on a deserted island and you find a radio. What's your next move?\",\n",
    "    \"Translate the following English sentence to French: 'The sun sets over the horizon.'\",\n",
    "    \"What are the primary differences between classical and quantum computing?\",\n",
    "    \"Describe the taste of a freshly picked apple.\",\n",
    "    \"You discover a mysterious old book in your attic with a lock on it. How would you approach this situation?\",\n",
    "    \"Write a SQL query to fetch all rows from the 'employees' table where the salary is greater than 50000.\",\n",
    "    \"What is the significance of the Schr√∂dinger's cat thought experiment in quantum mechanics?\",\n",
    "    \"Provide a Python code snippet to merge two dictionaries: \\ndef merge_dicts(dict1, dict2):\",\n",
    "    \"Briefly describe the process of photosynthesis.\",\n",
    "    \"Compose a limerick about a mischievous cat.\",\n",
    "    \"You're faced with a giant maze with a treasure in the center. How would you navigate it?\",\n",
    "    \"Translate the following English sentence to Spanish: 'The night sky is filled with stars.'\",\n",
    "    \"Explain the main components of a computer to someone from the 18th century.\",\n",
    "    \"Describe the sensation of diving into cold water on a hot day.\",\n",
    "    \"You hear a mysterious noise coming from the basement late at night. What's your reaction?\",\n",
    "    \"Provide a JavaScript function to toggle an element's visibility: \\nfunction toggleVisibility(elementId):\",\n",
    "    \"Outline the main events leading to World War II.\",\n",
    "    \"Write a sonnet about the passage of time.\",\n",
    "    \"You come across a talking frog claiming to be a prince. How do you respond?\",\n",
    "    \"Translate the following English phrase to German: 'Life is full of surprises.'\",\n",
    "    \"Discuss the impact of social media on modern communication.\",\n",
    "    \"Describe the aroma of fresh bread baking in an oven.\",\n",
    "    \"You find a time machine with a note saying it can take you to any one moment in history. Where and when do you choose to go?\",\n",
    "    \"Write a Java method to calculate the area of a rectangle: \\npublic double rectangleArea(double length, double width):\",\n",
    "    \"Detail the contributions of Nikola Tesla to the field of electricity.\",\n",
    "    \"Compose a short story about a dragon who loves to read books.\",\n",
    "    \"If you were to explain the internet to William Shakespeare, how would you describe it?\",\n",
    "    \"Describe the key benefits of adopting cloud computing in modern businesses.\",\n",
    "    \"Provide a summary of the principles of effective leadership in a corporate environment.\",\n",
    "    \"Draft an email to employees announcing a new sustainability initiative.\",\n",
    "    \"Outline the main challenges faced by global supply chains in the current economic climate.\",\n",
    "    \"Explain the significance of data analytics in shaping business strategies today.\",\n",
    "    \"Provide a brief overview of the concept of digital transformation and its impact on customer experience.\",\n",
    "    \"Discuss the role of corporate social responsibility (CSR) in enhancing a company's brand image.\",\n",
    "    \"Write a mission statement for a startup focused on renewable energy solutions.\",\n",
    "    \"Summarize the advantages of remote work for both employees and employers.\",\n",
    "    \"Describe the key factors that contribute to a positive organizational culture.\"\n",
    "]\n",
    "\n",
    "\n",
    "dataset_name = \"Input only subjective task dataset\"\n",
    "\n",
    "# Storing inputs in a dataset lets us\n",
    "# run chains and LLMs over a shared set of examples.\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Input only subjective tasks \",\n",
    ")\n",
    "\n",
    "for input_prompt in example_inputs:\n",
    "    # Each example must be unique and have inputs defined.\n",
    "    # Outputs are optional\n",
    "    client.create_example(\n",
    "        inputs={\"question\": input_prompt},\n",
    "        outputs=None,\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Optional\n",
    "from langchain.evaluation import StringEvaluator\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import openai_functions\n",
    "\n",
    "eval_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an impartial grader tasked with measuring the accuracy of responses.\"),\n",
    "        (\"human\", \"Please evaluate the following data:\\n\\n\"\n",
    "         \"<INPUT>\\n{input}</INPUT>\\n\"\n",
    "         \"<RESPONSE>\\n{prediction}</RESPONSE>\\n\"\n",
    "         \"Please save your reasoning and grading by calling the commit_grade function.\"\n",
    "         \" First, enumerate all factual discrepancies in the response.\"\n",
    "         \" Finally, score the prediction on a scale out of 100, taking into account factuality, conciseness and\"\n",
    "         \" correctness \"),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "commit_grade_schema = {\n",
    "    \"name\": \"commit_grade\",\n",
    "    \"description\": \"Commits a grade with reasoning.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"commit_grade_parameters\",\n",
    "        \"description\": \"Parameters for the commit_grade function.\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"mistakes\": {\n",
    "                \"title\": \"discrepancies\",\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any discrepencies between the predicted and ground truth.\"\n",
    "            },\n",
    "            \"reasoning\": {\n",
    "                \"title\": \"reasoning\",\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The explanation or logic behind the final grade.\"\n",
    "            },\n",
    "            \"grade\": {\n",
    "                \"title\": \"grade\",\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The numerical value representing the grade.\",\n",
    "                \"minimum\": 0,\n",
    "                \"maximum\": 100\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"reasoning\", \"grade\", \"mistakes\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "def normalize_grade(func_args: str) -> dict:\n",
    "    args = json.loads(func_args)\n",
    "    return {\n",
    "        \"reasoning\": (args.get(\"reasoning\", \"\") + \"\\n\\n\" + args.get(\"discrepancies\", \"\")).strip(),\n",
    "        \"score\": args.get(\"grade\", 0) / 100,\n",
    "    }\n",
    "\n",
    "eval_chain = (\n",
    "    eval_prompt\n",
    "    | ChatOpenAI(temperature=0).bind(functions=[commit_grade_schema])\n",
    "    | openai_functions.OutputFunctionsParser()\n",
    "    | normalize_grade\n",
    ")\n",
    "\n",
    "class EvaluateTriplets(StringEvaluator):\n",
    "    \"\"\"Evaluate the triplets of a predicted string.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def requires_input(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def requires_reference(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    def _evaluate_strings(\n",
    "        self,\n",
    "        *,\n",
    "        prediction: str,\n",
    "        reference: Optional[str] = None,\n",
    "        input: Optional[str] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> dict:\n",
    "        callbacks = kwargs.pop(\"callbacks\", None)\n",
    "        return eval_chain.invoke(\n",
    "            {\"prediction\": prediction, \"input\": input},\n",
    "            {\"callbacks\": callbacks},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f6d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Evaluate Datasets with LLM, the criteria here is \"informative-ness\"\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        # Or you can configure the evaluator\n",
    "        RunEvalConfig.Criteria(\"harmfulness\"),\n",
    "        RunEvalConfig.Criteria(\"misogyny\"),\n",
    "        RunEvalConfig.Criteria(\n",
    "            {\n",
    "                \"short_informative\": \"Are the answers short and informative? \"\n",
    "                \"Respond Y if they are, N if they're not short and informative.\"\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7781c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunEvalConfig(\n",
    "    custom_evaluators=[EvaluateTriplets()],\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"<s>[INST] {question} [/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2a843a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-crushing-point-36' at:\n",
      "https://smith.langchain.com/o/dcc925e6-6130-54c2-852e-9cbbb51328d6/projects/p/f05ee440-5312-4c1b-bb19-ba7bab8c7183\n",
      "[>                                                 ] 0/44"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 44/44"
     ]
    }
   ],
   "source": [
    "# Chat LLM\n",
    "llama_llm_chat = HuggingFacePipeline(pipeline=pipe_llama7b_chat)\n",
    "llama_chain_chat = prompt | llama_llm_chat\n",
    "results = await client.arun_on_dataset(\"Input only subjective task dataset\", llama_chain_chat, evaluation=eval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a81d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-back-flower-89' at:\n",
      "https://smith.langchain.com/o/dcc925e6-6130-54c2-852e-9cbbb51328d6/projects/p/d671ad3c-a73b-40bd-8149-ab219fefefb2\n",
      "[------->                                          ] 7/44"
     ]
    }
   ],
   "source": [
    "# Chat LLM w/ FT\n",
    "llama_llm_chat_ft = HuggingFacePipeline(pipeline=pipe_llama7b_ft_chat)\n",
    "llama_chain_chat_ft = prompt | llama_llm_chat_ft\n",
    "results = await client.arun_on_dataset(\"Input only subjective task dataset\", llama_chain_chat_ft, evaluation=eval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b82dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Create a Dataset From a List of Examples (Key-Value Pairs)\n",
    "\n",
    "example_inputs = [\n",
    "    (\"Complete the following Python function that computes the factorial of a number: \\ndef factorial(n):\", \"def factorial(n): \\n if n == 0: \\n return 1 \\n else: \\n return n * factorial(n-1)\"),\n",
    "    (\"Summarize the following paragraph: 'Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \\\"intelligent agents\\\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\", \n",
    "     \"AI is machine intelligence as opposed to natural human or animal intelligence. It's defined as the study of devices that act intelligently to achieve their goals.\"),\n",
    "    (\"You are in a dark room with a single door. There's a switch next to the door. What do you do?\", \"I would flip the switch to see if it turns on a light.\"),\n",
    "    (\n",
    "        \"Convert the following statement into a question: 'The Eiffel Tower is located in Paris.'\",\n",
    "        \"Where is the Eiffel Tower located?\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "dataset_name = \"Tasks and Answers\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Questions and answers about diverse tasks\",\n",
    ")\n",
    "\n",
    "for input_prompt, output_answer in example_inputs:\n",
    "    client.create_example(\n",
    "        inputs={\"question\": input_prompt},\n",
    "        outputs={\"answer\": output_answer},\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397a11a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textstat\n",
    "\n",
    "from typing import Optional\n",
    "from evaluate import load\n",
    "from langsmith.evaluation import EvaluationResult, RunEvaluator\n",
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "\n",
    "class FKEvaluator(RunEvaluator):\n",
    "    def __init__(self):\n",
    "        self.metric_fn = textstat.flesch_kincaid_grade\n",
    "\n",
    "    def evaluate_run(\n",
    "        self, run: Run, example: Optional[Example] = None\n",
    "    ) -> EvaluationResult:\n",
    "        if run.outputs is None:\n",
    "            raise ValueError(\"Run outputs cannot be None\")\n",
    "        prediction = run.outputs['generations'][0][0]['text']\n",
    "        return EvaluationResult(key=\"flesch_kincaid_grade\", score=self.metric_fn(prediction))\n",
    "    \n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        # You can define an arbitrary criterion as a key: value pair in the criteria dict\n",
    "        \"string_distance\",\n",
    "        \"embedding_distance\",\n",
    "        RunEvalConfig.Criteria(\"conciseness\"),\n",
    "        RunEvalConfig.LabeledCriteria(\n",
    "            {\n",
    "                \"helpfulness\": (\n",
    "                    \"Is this submission helpful to the user,\"\n",
    "                    \" taking into account the correct reference answer?\"\n",
    "                )\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    custom_evaluators = [FKEvaluator()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await client.arun_on_dataset(\"Tasks and Answers\", llama_chain_chat_ft, evaluation=eval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c29d80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
